{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cac89c63-71ce-4bd2-bab0-04c8641853f0",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Data\n",
    "data = pd.DataFrame({\n",
    "    'PropertyAge': [5, 15, 20, 3, 8, 12, 30, 25, 7, 18, 9, 10, 28, 6, 2],\n",
    "    'Price': [300000, 450000, 500000, 250000, 280000, 400000, 550000, 520000, 270000, 430000,\n",
    "              310000, 390000, 540000, 260000, 240000],\n",
    "    'NearSchool': [1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1],\n",
    "    'Sold': [1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1]\n",
    "})\n",
    "\n",
    "# Prepare features and target\n",
    "X = data[['PropertyAge', 'Price', 'NearSchool']]\n",
    "y = data['Sold']\n",
    "\n",
    "# Scale X to fix numeric range\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Add intercept\n",
    "X_scaled = sm.add_constant(X_scaled)\n",
    "\n",
    "# Fit logistic regression with regularization (ridge-like)\n",
    "model = sm.Logit(y, X_scaled)\n",
    "result = model.fit_regularized()\n",
    "\n",
    "# Print summary\n",
    "print(result.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00551102-2994-4842-9b47-4e2470ab1e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 8.185436037688933e-11\n",
      "            Iterations: 36\n",
      "            Function evaluations: 37\n",
      "            Gradient evaluations: 36\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                   Sold   No. Observations:                   15\n",
      "Model:                          Logit   Df Residuals:                       11\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Wed, 30 Jul 2025   Pseudo R-squ.:                   1.000\n",
      "Time:                        23:51:30   Log-Likelihood:            -1.2278e-09\n",
      "converged:                       True   LL-Null:                       -10.364\n",
      "Covariance Type:            nonrobust   LLR p-value:                 0.0001199\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -4.2943   2.43e+12  -1.76e-12      1.000   -4.77e+12    4.77e+12\n",
      "x1           -42.8676   5.36e+09     -8e-09      1.000   -1.05e+10    1.05e+10\n",
      "x2           -58.0348   8.37e+08  -6.93e-08      1.000   -1.64e+09    1.64e+09\n",
      "x3            26.4154   1.99e+12   1.33e-11      1.000   -3.89e+12    3.89e+12\n",
      "==============================================================================\n",
      "\n",
      "Complete Separation: The results show that there iscomplete separation or perfect prediction.\n",
      "In this case the Maximum Likelihood Estimator does not exist and the parameters\n",
      "are not identified.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Data\n",
    "data = pd.DataFrame({\n",
    "    'PropertyAge': [5, 15, 20, 3, 8, 12, 30, 25, 7, 18, 9, 10, 28, 6, 2],\n",
    "    'Price': [300000, 450000, 500000, 250000, 280000, 400000, 550000, 520000, 270000, 430000,\n",
    "              310000, 390000, 540000, 260000, 240000],\n",
    "    'NearSchool': [1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1],\n",
    "    'Sold': [1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1]\n",
    "})\n",
    "\n",
    "# Prepare features and target\n",
    "X = data[['PropertyAge', 'Price', 'NearSchool']]\n",
    "y = data['Sold']\n",
    "\n",
    "# Scale X to fix numeric range\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Add intercept\n",
    "X_scaled = sm.add_constant(X_scaled)\n",
    "\n",
    "# Fit logistic regression with regularization (ridge-like)\n",
    "model = sm.Logit(y, X_scaled)\n",
    "result = model.fit_regularized()\n",
    "\n",
    "# Print summary\n",
    "print(result.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9510fd7-e014-4701-9abf-ecf24ee36449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance ratio: [0.58511123 0.33850343 0.07638534]\n",
      "Singular values: [3.50532963 2.66619054 1.26652762]\n",
      "PCA components:\n",
      " [[-0.37187591  0.710658   -0.59722149]\n",
      " [ 0.84372711 -0.00951212 -0.53668806]\n",
      " [ 0.38708251  0.70347333  0.5960641 ]]\n",
      "\n",
      "Data in principal component space:\n",
      "         PC1       PC2       PC3\n",
      "0 -1.649689 -0.627544  0.236534\n",
      "1 -0.145061 -0.888610  0.134527\n",
      "2  2.204192 -0.714729 -0.104091\n",
      "3  0.851901 -0.799291 -0.160651\n",
      "4 -1.912706 -0.057309 -0.200811\n",
      "5  0.113504  1.597913 -0.803816\n",
      "6  0.537858  1.489570  0.898308\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Sample dataset: Replace this with your actual dataset\n",
    "data = pd.DataFrame({\n",
    "    'Feature1': [4, 2, 0, 1, 5, 6, 7],\n",
    "    'Feature2': [1, 3, 6, 4, 0, 2, 5],\n",
    "    'Feature3': [7, 5, 1, 3, 6, 0, 2]\n",
    "})\n",
    "\n",
    "# Step 1: Standardize the data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# Step 2: Apply PCA\n",
    "pca = PCA()\n",
    "pca_result = pca.fit(scaled_data)\n",
    "\n",
    "# Step 3: Explained variance\n",
    "print(\"Explained variance ratio:\", pca.explained_variance_ratio_)\n",
    "print(\"Singular values:\", pca.singular_values_)\n",
    "print(\"PCA components:\\n\", pca.components_)\n",
    "\n",
    "# Optional: Transform data to principal component space\n",
    "pca_data = pca.transform(scaled_data)\n",
    "pca_df = pd.DataFrame(pca_data, columns=[f'PC{i+1}' for i in range(pca_data.shape[1])])\n",
    "print(\"\\nData in principal component space:\\n\", pca_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846793aa-3b24-4194-aa6c-26be0898ba26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
